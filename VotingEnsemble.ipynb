{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c7b3cbc",
        "outputId": "8cffb309-c746-40f2-f7a3-73830e36b0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla V100-SXM2-16GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "id": "9c7b3cbc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItUa8o858wV8",
        "outputId": "29108ca9-3f8e-49c4-b619-20d1af889080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ItUa8o858wV8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "096fb121",
        "outputId": "50c5f4b8-8f15-43c6-b42b-64fa2ac605eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 568 kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ],
      "id": "096fb121"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjwL8iUr2Z0l"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string"
      ],
      "id": "vjwL8iUr2Z0l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b13de7f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Bert-Classfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        BERT paper suggestions for the hyperparameters during fine-tuning:\n",
        "        droupout: 0.1 ALWAYS\n",
        "        Batch size: 16, 32\n",
        "        Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "        Number of epochs: 2, 3, 4\n",
        "\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 8\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "          \"\"\"\n",
        "          Feed input to BERT and the classifier to compute logits.\n",
        "          @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                        max_length)\n",
        "          @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                        information with shape (batch_size, max_length)\n",
        "          @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                        num_labels)\n",
        "          \"\"\"\n",
        "          # Feed input to BERT\n",
        "          outputs = self.bert(input_ids=input_ids,\n",
        "                              attention_mask=attention_mask)\n",
        "          \n",
        "          # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "          last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "          # Feed input to classifier to compute logits\n",
        "          logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "          return logits\n",
        "        "
      ],
      "id": "2b13de7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba0e681f"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "def initialize_model(model_name,train_dataloader,epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(model_name,freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=2e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "id": "ba0e681f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB0sIPCk7qTA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "set_seed(42)    # Set seed for reproducibility"
      ],
      "id": "DB0sIPCk7qTA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XReE-Owt7V3D"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    # Tracking variables\n",
        "    val_loss = []\n",
        "    val_tp=[]\n",
        "    val_fp=[]\n",
        "    val_tn=[]\n",
        "    val_fn=[]\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        val_tp.append((((preds+1)/(b_labels+1)) == b_labels).cpu().numpy().sum())\n",
        "        val_fp.append((preds - b_labels == 1).cpu().numpy().sum())\n",
        "        val_tn.append((((preds+1)/(b_labels+1)) == b_labels+1).cpu().numpy().sum())\n",
        "        val_fn.append((preds - b_labels == -1).cpu().numpy().sum())\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    # predictions = np.concatenate(predictions, axis=0)\n",
        "    # true_vals = np.concatenate(true_vals, axis=0)\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_tp=np.sum(val_tp)\n",
        "    val_fp=np.sum(val_fp)\n",
        "    val_tn=np.sum(val_tn)\n",
        "    val_fn=np.sum(val_fn)\n",
        "    pos= val_fn + val_tp\n",
        "    neg = val_fp +val_tn\n",
        "    total = pos + neg\n",
        "    val_accuracy=(val_tp+val_tn)/(val_tp+val_tn+val_fp+val_fn)\n",
        "    # val_neg_f1=(2*val_tn)/( val_tn + val_fn +neg)\n",
        "    # val_pos_f1=(2*val_tp)/( val_tp + val_fp +pos)\n",
        "    precison= val_tp/(val_tp+val_fp)\n",
        "    recall= val_tp/(val_tp+val_fn)\n",
        "    labels_flat = b_labels.flatten()\n",
        "    F1= (2*precison*recall)/(precison+recall)\n",
        "    # if(acc_per_class):\n",
        "    #   accuracy_per_class(predictions, true_vals)\n",
        "    \n",
        "    # microF1 = (val_neg_f1 * neg + val_pos_f1 * pos)/ total\n",
        "    return val_loss, val_accuracy ,precison, recall, F1"
      ],
      "id": "XReE-Owt7V3D"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, test_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    # Tracking variables\n",
        "    predictions=[]\n",
        "    labels=[]\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "            \n",
        "        # Get the true labels\n",
        "        labels.append(b_labels.flatten().cpu())\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        predictions.append(preds.cpu())\n",
        "    return predictions, labels"
      ],
      "metadata": {
        "id": "sgHF3gxFaV2t"
      },
      "id": "sgHF3gxFaV2t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### bert preprocessing\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "# model_name='aubmindlab/bert-base-arabertv2'\n",
        "# model_name='CAMeL-Lab/bert-base-arabic-camelbert-msa'\n",
        "# model_name='UBC-NLP/MARBERTv2'\n",
        "# model_name=\"UBC-NLP/ARBERT\"\n",
        "def preprocessing_for_bert(data,model_name):\n",
        "  \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  \n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    MAX_LEN=350 # it can be assigned to average: 90 token, what do you think?\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,\n",
        "            truncation =True,         # Pad sentence to max length\n",
        "            return_attention_mask=True \n",
        "                        )    \n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "MU9uyEC9ddD8"
      },
      "id": "MU9uyEC9ddD8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX3QzTvUsCIp"
      },
      "outputs": [],
      "source": [
        "#Loading data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Saudi Patent Research Project 2022/colab/model_dataset.csv')"
      ],
      "id": "iX3QzTvUsCIp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wYNHds593oyo",
        "outputId": "5335b21c-d65f-4feb-e824-9897faacd36a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               text label  \\\n",
              "0              0  طريقة وجهاز لكشف وحدة الشبكة البصرية ونظام الش...     H   \n",
              "1              1  جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...     F   \n",
              "2              2  طريقة لمعالجة سطح صبغة ثاني أكسيد التيتانيوميت...     C   \n",
              "3              3  طريقة للمحاكاة الآمنة للكشف عن التلوث بمادة مش...     G   \n",
              "4              4  جهاز لتغيير عربة تحميليتعلق الاختراع الراهن بج...     F   \n",
              "...          ...                                                ...   ...   \n",
              "9760        9760  مركبات أمينوجوانيدينات، والتركيبات الصيديلية ا...     A   \n",
              "9761        9761  مثبطات HIV PROTEASE  في تركيبات صيدلية لعلاج ا...     A   \n",
              "9762        9762  حفازات عالية الفعالية ذات بنية مسامية أوسطية ث...     C   \n",
              "9763        9763  hemihydrate of 4-(5,6,7,8-tetrahydroimidazo[1,...     A   \n",
              "9764        9764  ناقلة بحرية  BARGES مرنة من FLEXIBLE  القماش F...     B   \n",
              "\n",
              "                                           cleaned_text  \n",
              "0     طريقه وجهاز لكشف وحده الشبكه البصريه ونظام الش...  \n",
              "1     جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...  \n",
              "2     طريقه لمعالجه سطح صبغه ثاني اكسيد التيتانيوميت...  \n",
              "3     طريقه للمحاكاه الامنه للكشف عن التلوث بماده مش...  \n",
              "4     جهاز لتغير عربه تحميليتعلق الاختراع الراهن بجه...  \n",
              "...                                                 ...  \n",
              "9760  مركبات امينوجوانيدينات والتركيبات الصيديليه ال...  \n",
              "9761  مثبطات HIV PROTEASE  في تركيبات صيدليه لعلاج ا...  \n",
              "9762  حفازات عاليه الفعاليه ذات بنيه مساميه اوسطيه ث...  \n",
              "9763  hemihydrate of tetrahydroimidazoa pyridineN be...  \n",
              "9764  ناقله بحريه  BARGES مرنه من FLEXIBLE  القماش F...  \n",
              "\n",
              "[9765 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f80a7ae9-a11a-497c-9e2d-8ccf75d190e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>طريقة وجهاز لكشف وحدة الشبكة البصرية ونظام الش...</td>\n",
              "      <td>H</td>\n",
              "      <td>طريقه وجهاز لكشف وحده الشبكه البصريه ونظام الش...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...</td>\n",
              "      <td>F</td>\n",
              "      <td>جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>طريقة لمعالجة سطح صبغة ثاني أكسيد التيتانيوميت...</td>\n",
              "      <td>C</td>\n",
              "      <td>طريقه لمعالجه سطح صبغه ثاني اكسيد التيتانيوميت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>طريقة للمحاكاة الآمنة للكشف عن التلوث بمادة مش...</td>\n",
              "      <td>G</td>\n",
              "      <td>طريقه للمحاكاه الامنه للكشف عن التلوث بماده مش...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>جهاز لتغيير عربة تحميليتعلق الاختراع الراهن بج...</td>\n",
              "      <td>F</td>\n",
              "      <td>جهاز لتغير عربه تحميليتعلق الاختراع الراهن بجه...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9760</th>\n",
              "      <td>9760</td>\n",
              "      <td>مركبات أمينوجوانيدينات، والتركيبات الصيديلية ا...</td>\n",
              "      <td>A</td>\n",
              "      <td>مركبات امينوجوانيدينات والتركيبات الصيديليه ال...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9761</th>\n",
              "      <td>9761</td>\n",
              "      <td>مثبطات HIV PROTEASE  في تركيبات صيدلية لعلاج ا...</td>\n",
              "      <td>A</td>\n",
              "      <td>مثبطات HIV PROTEASE  في تركيبات صيدليه لعلاج ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9762</th>\n",
              "      <td>9762</td>\n",
              "      <td>حفازات عالية الفعالية ذات بنية مسامية أوسطية ث...</td>\n",
              "      <td>C</td>\n",
              "      <td>حفازات عاليه الفعاليه ذات بنيه مساميه اوسطيه ث...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9763</th>\n",
              "      <td>9763</td>\n",
              "      <td>hemihydrate of 4-(5,6,7,8-tetrahydroimidazo[1,...</td>\n",
              "      <td>A</td>\n",
              "      <td>hemihydrate of tetrahydroimidazoa pyridineN be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9764</th>\n",
              "      <td>9764</td>\n",
              "      <td>ناقلة بحرية  BARGES مرنة من FLEXIBLE  القماش F...</td>\n",
              "      <td>B</td>\n",
              "      <td>ناقله بحريه  BARGES مرنه من FLEXIBLE  القماش F...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9765 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f80a7ae9-a11a-497c-9e2d-8ccf75d190e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f80a7ae9-a11a-497c-9e2d-8ccf75d190e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f80a7ae9-a11a-497c-9e2d-8ccf75d190e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df"
      ],
      "id": "wYNHds593oyo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po_E93t83zqU"
      },
      "outputs": [],
      "source": [
        "df=df.drop('Unnamed: 0', axis=1)\n",
        "df= df.dropna()"
      ],
      "id": "Po_E93t83zqU"
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eagt3UAg5KpW",
        "outputId": "6776ea89-1c96-4be8-beb9-173c41a81ebf"
      },
      "id": "eagt3UAg5KpW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text label  \\\n",
              "0     طريقة وجهاز لكشف وحدة الشبكة البصرية ونظام الش...     H   \n",
              "1     جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...     F   \n",
              "2     طريقة لمعالجة سطح صبغة ثاني أكسيد التيتانيوميت...     C   \n",
              "3     طريقة للمحاكاة الآمنة للكشف عن التلوث بمادة مش...     G   \n",
              "4     جهاز لتغيير عربة تحميليتعلق الاختراع الراهن بج...     F   \n",
              "...                                                 ...   ...   \n",
              "9760  مركبات أمينوجوانيدينات، والتركيبات الصيديلية ا...     A   \n",
              "9761  مثبطات HIV PROTEASE  في تركيبات صيدلية لعلاج ا...     A   \n",
              "9762  حفازات عالية الفعالية ذات بنية مسامية أوسطية ث...     C   \n",
              "9763  hemihydrate of 4-(5,6,7,8-tetrahydroimidazo[1,...     A   \n",
              "9764  ناقلة بحرية  BARGES مرنة من FLEXIBLE  القماش F...     B   \n",
              "\n",
              "                                           cleaned_text  \n",
              "0     طريقه وجهاز لكشف وحده الشبكه البصريه ونظام الش...  \n",
              "1     جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...  \n",
              "2     طريقه لمعالجه سطح صبغه ثاني اكسيد التيتانيوميت...  \n",
              "3     طريقه للمحاكاه الامنه للكشف عن التلوث بماده مش...  \n",
              "4     جهاز لتغير عربه تحميليتعلق الاختراع الراهن بجه...  \n",
              "...                                                 ...  \n",
              "9760  مركبات امينوجوانيدينات والتركيبات الصيديليه ال...  \n",
              "9761  مثبطات HIV PROTEASE  في تركيبات صيدليه لعلاج ا...  \n",
              "9762  حفازات عاليه الفعاليه ذات بنيه مساميه اوسطيه ث...  \n",
              "9763  hemihydrate of tetrahydroimidazoa pyridineN be...  \n",
              "9764  ناقله بحريه  BARGES مرنه من FLEXIBLE  القماش F...  \n",
              "\n",
              "[9765 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5aa8d49b-8109-44b4-8df8-3c406f2a4634\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>طريقة وجهاز لكشف وحدة الشبكة البصرية ونظام الش...</td>\n",
              "      <td>H</td>\n",
              "      <td>طريقه وجهاز لكشف وحده الشبكه البصريه ونظام الش...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...</td>\n",
              "      <td>F</td>\n",
              "      <td>جهاز لتبريد الهواء الداخل لمحرك احتراق داخلي ث...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>طريقة لمعالجة سطح صبغة ثاني أكسيد التيتانيوميت...</td>\n",
              "      <td>C</td>\n",
              "      <td>طريقه لمعالجه سطح صبغه ثاني اكسيد التيتانيوميت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>طريقة للمحاكاة الآمنة للكشف عن التلوث بمادة مش...</td>\n",
              "      <td>G</td>\n",
              "      <td>طريقه للمحاكاه الامنه للكشف عن التلوث بماده مش...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>جهاز لتغيير عربة تحميليتعلق الاختراع الراهن بج...</td>\n",
              "      <td>F</td>\n",
              "      <td>جهاز لتغير عربه تحميليتعلق الاختراع الراهن بجه...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9760</th>\n",
              "      <td>مركبات أمينوجوانيدينات، والتركيبات الصيديلية ا...</td>\n",
              "      <td>A</td>\n",
              "      <td>مركبات امينوجوانيدينات والتركيبات الصيديليه ال...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9761</th>\n",
              "      <td>مثبطات HIV PROTEASE  في تركيبات صيدلية لعلاج ا...</td>\n",
              "      <td>A</td>\n",
              "      <td>مثبطات HIV PROTEASE  في تركيبات صيدليه لعلاج ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9762</th>\n",
              "      <td>حفازات عالية الفعالية ذات بنية مسامية أوسطية ث...</td>\n",
              "      <td>C</td>\n",
              "      <td>حفازات عاليه الفعاليه ذات بنيه مساميه اوسطيه ث...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9763</th>\n",
              "      <td>hemihydrate of 4-(5,6,7,8-tetrahydroimidazo[1,...</td>\n",
              "      <td>A</td>\n",
              "      <td>hemihydrate of tetrahydroimidazoa pyridineN be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9764</th>\n",
              "      <td>ناقلة بحرية  BARGES مرنة من FLEXIBLE  القماش F...</td>\n",
              "      <td>B</td>\n",
              "      <td>ناقله بحريه  BARGES مرنه من FLEXIBLE  القماش F...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9765 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aa8d49b-8109-44b4-8df8-3c406f2a4634')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5aa8d49b-8109-44b4-8df8-3c406f2a4634 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5aa8d49b-8109-44b4-8df8-3c406f2a4634');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GId8wODG4Fl9",
        "outputId": "4d9423e8-5a44-41f1-e0ee-189bba1c5721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'H': 0, 'F': 1, 'C': 2, 'G': 3, 'B': 4, 'A': 5, 'E': 6, 'D': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "possible_labels = df.label.unique()\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "id": "GId8wODG4Fl9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5hn01rqsNO4"
      },
      "outputs": [],
      "source": [
        "df['label'] = df.label.replace(label_dict)\n",
        "X = df.text.values\n",
        "y = df.label.values\n",
        "y=y.astype(int)\n",
        "### converting labels to tensors and intilizing batches\n",
        "labels = torch.tensor(y)"
      ],
      "id": "-5hn01rqsNO4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2SBVTyvbEdX",
        "outputId": "6ad1ef28-b86a-4742-9d81-baba033b82b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# model_name='aubmindlab/bert-base-arabertv2'\n",
        "# model_name='CAMeL-Lab/bert-base-arabic-camelbert-mix'\n",
        "# model_name='UBC-NLP/MARBERTv2'\n",
        "# model_name=\"UBC-NLP/ARBERT\"\n",
        "# model_name=\"qarib/bert-base-qarib\"\n",
        "model_names=['CAMeL-Lab/bert-base-arabic-camelbert-msa',\"CAMeL-Lab/bert-base-arabic-camelbert-mix\", 'aubmindlab/bert-base-arabertv2']\n",
        "# Stratified shuffle split the data into 80/10/10\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_valid_index in split.split(X, labels):\n",
        "    train_set = X[train_index]\n",
        "    train_labels=labels[train_index]\n",
        "    test_valid_set = X[test_valid_index]\n",
        "    test_valid_set_labels=labels[test_valid_index]\n",
        "\n",
        "split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "for test_index, valid_index in split2.split(test_valid_set, test_valid_set_labels):\n",
        "    test_set = test_valid_set[test_index]\n",
        "    val_set = test_valid_set[valid_index]\n",
        "    test_labels=test_valid_set_labels[test_index]\n",
        "    val_labels=test_valid_set_labels[valid_index]\n",
        "\n",
        "print('Tokenizing data...')\n",
        "test_inputs_CAMEL,test_masks_CAMEL=preprocessing_for_bert(test_set,model_names[0])\n",
        "test_inputs_MIX,test_masks_MIX=preprocessing_for_bert(test_set,model_names[1])\n",
        "test_inputs_ARABERT,test_masks_ARABERT=preprocessing_for_bert(test_set,model_names[2])\n",
        "\n",
        "train_inputs_CAMEL,train_masks_CAMEL=preprocessing_for_bert(train_set,model_names[0])\n",
        "train_inputs_MIX,train_masks_MIX=preprocessing_for_bert(train_set,model_names[1])\n",
        "train_inputs_ARABERT,train_masks_ARABERT=preprocessing_for_bert(train_set,model_names[2])"
      ],
      "id": "F2SBVTyvbEdX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsrQaoN5NR-F"
      },
      "outputs": [],
      "source": [
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data_CAMEL = TensorDataset(train_inputs_CAMEL, train_masks_CAMEL, train_labels)\n",
        "train_sampler_CAMEL = RandomSampler(train_data_CAMEL)\n",
        "train_dataloader_CAMEL = DataLoader(train_data_CAMEL, sampler=train_sampler_CAMEL, batch_size=batch_size)\n",
        "\n",
        "\n",
        "train_data_MIX = TensorDataset(train_inputs_MIX, train_masks_MIX, train_labels)\n",
        "train_sampler_MIX = RandomSampler(train_data_MIX)\n",
        "train_dataloader_MIX = DataLoader(train_data_MIX, sampler=train_sampler_MIX, batch_size=batch_size)\n",
        "\n",
        "\n",
        "train_data_ARABERT = TensorDataset(train_inputs_ARABERT, train_masks_ARABERT, train_labels)\n",
        "train_sampler_ARABERT = RandomSampler(train_data_ARABERT)\n",
        "train_dataloader_ARABERT = DataLoader(train_data_ARABERT, sampler=train_sampler_ARABERT, batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# Create the DataLoader for our Testing set\n",
        "test_data_CAMEL = TensorDataset(test_inputs_CAMEL, test_masks_CAMEL, test_labels)\n",
        "test_sampler_CAMEL = SequentialSampler(test_data_CAMEL)\n",
        "test_dataloader_CAMEL = DataLoader(test_data_CAMEL, sampler=test_sampler_CAMEL, batch_size=batch_size)\n",
        "\n",
        "test_data_MIX = TensorDataset(test_inputs_MIX, test_masks_MIX, test_labels)\n",
        "test_sampler_MIX = SequentialSampler(test_data_MIX)\n",
        "test_dataloader_MIX = DataLoader(test_data_MIX, sampler=test_sampler_MIX, batch_size=batch_size)\n",
        "\n",
        "test_data_ARABERT = TensorDataset(test_inputs_ARABERT, test_masks_ARABERT, test_labels)\n",
        "test_sampler_ARABERT = SequentialSampler(test_data_ARABERT)\n",
        "test_dataloader_ARABERT = DataLoader(test_data_ARABERT, sampler=test_sampler_ARABERT, batch_size=batch_size)\n",
        "\n"
      ],
      "id": "vsrQaoN5NR-F"
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize and load previously trained models\n",
        "MIX, MIX_optimizer, MIX_scheduler = initialize_model(model_names[1],train_dataloader_MIX,epochs=3)\n",
        "CAMEL, CAMEL_optimizer, CAMEL_scheduler = initialize_model(model_names[0],train_dataloader_CAMEL, epochs=3)\n",
        "ARABERT, ARABERT_optimizer, ARABERT_scheduler = initialize_model(model_names[2],train_dataloader_ARABERT,epochs=3)\n",
        "MIX.load_state_dict(torch.load('/content/drive/MyDrive/Saudi Patent Research Project 2022/saved_models/camel_mix_unprocessed'))\n",
        "CAMEL.load_state_dict(torch.load('/content/drive/MyDrive/Saudi Patent Research Project 2022/saved_models/CAMEL_MSA'))\n",
        "ARABERT.load_state_dict(torch.load('/content/drive/MyDrive/Saudi Patent Research Project 2022/saved_models/arabertv2_unprocessed'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZTgYlc2Ftu7",
        "outputId": "c6cad07f-3de3-4527-c649-63ed88618f8d"
      },
      "id": "OZTgYlc2Ftu7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-mix were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-msa were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIX_preds, MIX_labels= get_predictions(MIX, test_dataloader_MIX)\n",
        "CAMEL_preds, CAMEL_labels= get_predictions(CAMEL, test_dataloader_CAMEL)\n",
        "ARABERT_preds, ARABERT_labels= get_predictions(ARABERT, test_dataloader_ARABERT)"
      ],
      "metadata": {
        "id": "43eqZh6fYb3-"
      },
      "id": "43eqZh6fYb3-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds= { 'MIX':MIX_preds, 'CAMEL':CAMEL_preds, 'ARABERT':ARABERT_preds }"
      ],
      "metadata": {
        "id": "JfBs_ERTcGrV"
      },
      "id": "JfBs_ERTcGrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preds['MIX']))\n",
        "print(len(preds['CAMEL']))\n",
        "print(len(preds['ARABERT']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa1Y1E71gZmA",
        "outputId": "c44668c1-b268-4986-dd2c-dccce92c69a6"
      },
      "id": "Wa1Y1E71gZmA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "31\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np_MIX_preds= [i.detach().numpy() for i in preds['MIX']]\n",
        "np_CAMEL_preds= [i.detach().numpy() for i in preds['CAMEL']]\n",
        "np_ARABERT_preds= [i.detach().numpy() for i in preds['ARABERT']]\n",
        "true_labels=[i.detach().numpy() for i in CAMEL_labels]"
      ],
      "metadata": {
        "id": "BeTu1VTai_qK"
      },
      "id": "BeTu1VTai_qK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_sum(elm1, elm2, elm3):\n",
        "   elm1_=[0,0,0,0,0,0,0,0]\n",
        "   elm2_=[0,0,0,0,0,0,0,0]\n",
        "   elm3_=[0,0,0,0,0,0,0,0]\n",
        "   elm1_[elm1]=1\n",
        "   elm2_[elm2]=1\n",
        "   elm3_[elm3]=1\n",
        "   summed = np.tensordot([elm1_,elm2_,elm3_],[1,0.5,0.5], axes=((0),(0)))\n",
        "   result = np.argmax(summed)\n",
        "   return result\n"
      ],
      "metadata": {
        "id": "ezo-lCZZXZfc"
      },
      "id": "ezo-lCZZXZfc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "voting ensemble (weighted)"
      ],
      "metadata": {
        "id": "wGcQErrDGvPJ"
      },
      "id": "wGcQErrDGvPJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# LOOKING FOR A WAY TO IMPLEMENT IT\n",
        "majority_vote=[]\n",
        "for i in range(31):\n",
        "  \n",
        "  if(i==30):\n",
        "    result=[]\n",
        "    for j in range(16):\n",
        "      mod=weighted_sum(np_CAMEL_preds[i][j],np_MIX_preds[i][j],np_ARABERT_preds[i][j])\n",
        "      result = np.append(result, mod)\n",
        "  else:\n",
        "    result=[]\n",
        "    for j in range(32):\n",
        "      mod=weighted_sum(np_CAMEL_preds[i][j],np_MIX_preds[i][j],np_ARABERT_preds[i][j])\n",
        "      result = np.append(result, mod)\n",
        "  majority_vote.append(np.array(result, dtype=np.int8))"
      ],
      "metadata": {
        "id": "PuwV-AYSGzYA"
      },
      "id": "PuwV-AYSGzYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predictions\n",
        "val_tp=[]\n",
        "val_fp=[]\n",
        "val_tn=[]\n",
        "val_fn=[]\n",
        "for i in range(31):\n",
        "    val_tp.append((((majority_vote[i]+1)/(true_labels[i]+1)) == true_labels[i]).sum())\n",
        "    val_fp.append((majority_vote[i] - true_labels[i] == 1).sum())\n",
        "    val_tn.append((((majority_vote[i]+1)/(true_labels[i]+1)) == true_labels[i]+1).sum())\n",
        "    val_fn.append((majority_vote[i] - true_labels[i] == -1).sum())\n",
        "val_tp=np.sum(val_tp)\n",
        "val_fp=np.sum(val_fp)\n",
        "val_tn=np.sum(val_tn)\n",
        "val_fn=np.sum(val_fn)\n",
        "pos= val_fn + val_tp\n",
        "neg = val_fp +val_tn\n",
        "total = pos + neg\n",
        "val_accuracy=(val_tp+val_tn)/(val_tp+val_tn+val_fp+val_fn)\n",
        "precison= val_tp/(val_tp+val_fp)\n",
        "recall= val_tp/(val_tp+val_fn)\n",
        "F1= (2*precison*recall)/(precison+recall)"
      ],
      "metadata": {
        "id": "2FoyznuqpkIu"
      },
      "id": "2FoyznuqpkIu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted sum Ensemble results\n",
        "print(f\"  {' Acc':^8}  |{'  precison ':^8}|{' recall ':^8} |{' F1':^8} \") \n",
        "print(f\"  {val_accuracy:^9f} | {precison:^9f} |{recall:^9f} |{F1:^9f} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QPI7ehCXE-e",
        "outputId": "665fff4b-e5bc-4af6-e032-4210455ed2af"
      },
      "id": "2QPI7ehCXE-e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Acc    |  precison | recall  |   F1    \n",
            "  0.770588  | 0.844037  |0.807018  |0.825112  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model on test data:\n",
        "val_loss, val_accuracy ,precison, recall, F1= evaluate(CAMEL, test_dataloader_CAMEL)\n",
        "print(f\" {' Loss':^10} | {' Acc':^8}  |{'  precison ':^8}|{' recall ':^8} |{' F1':^8} \") \n",
        "print(f\" { val_loss:^10.6f} | {val_accuracy:^9f} | {precison:^9f} |{recall:^9f} |{F1:^9f} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmSM2pgsU4iu",
        "outputId": "58df3a8f-8a8c-4271-d8f3-0ba0dfcc7202"
      },
      "id": "wmSM2pgsU4iu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Loss    |    Acc    |  precison | recall  |   F1    \n",
            "  0.895033  | 0.760234  | 0.827273  |0.805310  |0.816143  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "HardVotingClassification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}